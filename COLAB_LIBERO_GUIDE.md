# Google Colabì—ì„œ LIBERO Evaluation ì‹¤í–‰ ê°€ì´ë“œ
# Guide for Running LIBERO Evaluation on Google Colab

[í•œêµ­ì–´](#í•œêµ­ì–´-ê°€ì´ë“œ) | [English](#english-guide)

---

## í•œêµ­ì–´ ê°€ì´ë“œ

### ğŸ¯ ê°œìš”

ì´ ê°€ì´ë“œëŠ” Google Colabì—ì„œ OpenVLAì˜ LIBERO Simulation Benchmark Evaluationsë¥¼ ì‹¤í–‰í•  ë•Œ ë°œìƒí•˜ëŠ” ì¼ë°˜ì ì¸ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

### âš ï¸ ì£¼ìš” ë¬¸ì œì ë“¤

Colabì—ì„œ LIBERO evaluationì„ ì‹¤í–‰í•  ë•Œ ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œë“¤ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **Flash Attention 2 í˜¸í™˜ì„± ë¬¸ì œ**
   - Colabì˜ GPU (íŠ¹íˆ T4)ì—ì„œ Flash Attention 2ê°€ ì§€ì›ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
   - CUDA ë²„ì „ ë¶ˆì¼ì¹˜ë¡œ ì¸í•œ ì„¤ì¹˜ ì‹¤íŒ¨

2. **8ë¹„íŠ¸ ì–‘ìí™” ì˜¤ë¥˜**
   - `bitsandbytes` ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ transformers ë²„ì „ ì¶©ëŒ
   - CUDA ì»¤ë„ ë¡œë”© ì‹¤íŒ¨

3. **Dependency í˜¸í™˜ì„± ë¬¸ì œ**
   - PyTorch, transformers, tokenizers ë²„ì „ ë¶ˆì¼ì¹˜
   - Colabì˜ ê¸°ë³¸ ì„¤ì¹˜ íŒ¨í‚¤ì§€ì™€ ì¶©ëŒ

4. **ë©”ëª¨ë¦¬ ë¶€ì¡±**
   - T4 GPU (16GB)ì—ì„œ 7B ëª¨ë¸ ë¡œë”© ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡±
   - bfloat16ìœ¼ë¡œë„ ì•½ 14GB í•„ìš”

### ğŸš€ ë¹ ë¥¸ ì‹œì‘ (Colabì—ì„œ ì‹¤í–‰)

#### 1ë‹¨ê³„: ì €ì¥ì†Œ í´ë¡  ë° ì„¤ì •

```bash
# Colab ë…¸íŠ¸ë¶ì—ì„œ ì‹¤í–‰
!git clone https://github.com/openvla/openvla.git
%cd openvla

# Colab ì „ìš© ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
!python experiments/robot/libero/colab_setup_libero.py
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìë™ìœ¼ë¡œ:
- GPU íƒ€ì… ê°ì§€ (T4, V100, A100 ë“±)
- ì ì ˆí•œ dependency ë²„ì „ ì„¤ì¹˜
- Flash Attention ì„¤ì¹˜ ì‹œë„ (ì‹¤íŒ¨í•´ë„ OK)
- LIBERO ë° í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
- ë¬¸ì œ í•´ê²° íŒ ì œê³µ

#### 2ë‹¨ê³„: Evaluation ì‹¤í–‰

**A. V100/A100 GPUì˜ ê²½ìš° (ì–‘ìí™” ì—†ì´):**
```bash
!python experiments/robot/libero/run_libero_eval.py \
  --model_family openvla \
  --pretrained_checkpoint openvla/openvla-7b-finetuned-libero-spatial \
  --task_suite_name libero_spatial \
  --center_crop True
```

**B. T4 GPUì˜ ê²½ìš° (8ë¹„íŠ¸ ì–‘ìí™” ì‚¬ìš©):**
```bash
!python experiments/robot/libero/run_libero_eval.py \
  --model_family openvla \
  --pretrained_checkpoint openvla/openvla-7b-finetuned-libero-spatial \
  --task_suite_name libero_spatial \
  --center_crop True \
  --load_in_8bit True
```

### ğŸ”§ ë¬¸ì œ í•´ê²°

#### Flash Attention ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°

```
ValueError: FlashAttention only support fp16 and bf16 data type
```

**í•´ê²°ì±…**: ì œê³µëœ Colab ìµœì í™” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ìë™ìœ¼ë¡œ eager attentionìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.

```bash
# experiments/robot/openvla_utils.py ëŒ€ì‹  Colab ë²„ì „ ì‚¬ìš©
!cp experiments/robot/openvla_utils_colab.py experiments/robot/openvla_utils.py
```

#### 8ë¹„íŠ¸ ì–‘ìí™” ì˜¤ë¥˜

```
RuntimeError: CUDA error: no kernel image is available for execution on the device
```

**í•´ê²°ì±… 1**: bitsandbytes ìµœì‹  ë²„ì „ ì„¤ì¹˜
```bash
!pip install bitsandbytes>=0.43.0 --upgrade
```

**í•´ê²°ì±… 2**: ì–‘ìí™” ì—†ì´ ì‹¤í–‰ (V100/A100ì—ì„œë§Œ)
```bash
# --load_in_8bit ì˜µì…˜ ì œê±°
```

#### CUDA Out of Memory

```
torch.cuda.OutOfMemoryError: CUDA out of memory
```

**í•´ê²°ì±… 1**: 8ë¹„íŠ¸ ì–‘ìí™” ì‚¬ìš©
```bash
--load_in_8bit True
```

**í•´ê²°ì±… 2**: trials ìˆ˜ ì¤„ì´ê¸°
```bash
--num_trials_per_task 10  # ê¸°ë³¸ê°’ 50ì—ì„œ ì¤„ì„
```

**í•´ê²°ì±… 3**: ëŸ°íƒ€ì„ ì¬ì‹œì‘ ë° ë©”ëª¨ë¦¬ ì •ë¦¬
```python
import torch
torch.cuda.empty_cache()
```

#### Dependency ë²„ì „ ì¶©ëŒ

```
ImportError: cannot import name 'xxx' from 'transformers'
```

**í•´ê²°ì±…**: ì •í™•í•œ ë²„ì „ ì¬ì„¤ì¹˜
```bash
!pip uninstall -y transformers tokenizers timm
!pip install transformers==4.40.1 tokenizers==0.19.1 timm==0.9.10
```

### ğŸ“Š ë‹¤ë¥¸ Task Suites ì‹¤í–‰

```bash
# LIBERO-Object
!python experiments/robot/libero/run_libero_eval.py \
  --model_family openvla \
  --pretrained_checkpoint openvla/openvla-7b-finetuned-libero-object \
  --task_suite_name libero_object \
  --center_crop True \
  --load_in_8bit True

# LIBERO-Goal
!python experiments/robot/libero/run_libero_eval.py \
  --model_family openvla \
  --pretrained_checkpoint openvla/openvla-7b-finetuned-libero-goal \
  --task_suite_name libero_goal \
  --center_crop True \
  --load_in_8bit True

# LIBERO-10 (Long Horizon)
!python experiments/robot/libero/run_libero_eval.py \
  --model_family openvla \
  --pretrained_checkpoint openvla/openvla-7b-finetuned-libero-10 \
  --task_suite_name libero_10 \
  --center_crop True \
  --load_in_8bit True
```

### ğŸ’¡ Colab Pro íŒ

1. **GPU ì„ íƒ**: Runtime > Change runtime type > GPU (T4, V100, or A100)
2. **ë©”ëª¨ë¦¬ ì‚¬ìš© ëª¨ë‹ˆí„°ë§**:
   ```python
   !nvidia-smi
   ```
3. **ì„¸ì…˜ ìœ ì§€**: Colabì´ ìë™ìœ¼ë¡œ ì—°ê²°ì„ ëŠì§€ ì•Šë„ë¡ ì£¼ì˜
4. **ê²°ê³¼ ì €ì¥**: Google Driveì— ë§ˆìš´íŠ¸í•˜ì—¬ ë¡œê·¸ ì €ì¥
   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   ```

### ğŸ“ ë…¼ë¬¸ ì¬í˜„ì„ ìœ„í•œ ê¶Œì¥ ì‚¬í•­

ë…¼ë¬¸ì˜ ê²°ê³¼ë¥¼ ì •í™•íˆ ì¬í˜„í•˜ë ¤ë©´:

- **Python**: 3.10.13
- **PyTorch**: 2.2.0
- **transformers**: 4.40.1
- **flash-attn**: 2.5.5
- **GPU**: NVIDIA A100

âš ï¸ **ì£¼ì˜**: Colabì˜ ë¬´ë£Œ T4 GPUì—ì„œëŠ” ì •í™•í•œ ì¬í˜„ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²°ê³¼ê°€ ì•½ê°„ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ“ ì™„ì „í•œ Colab ë…¸íŠ¸ë¶ ì˜ˆì œ

```python
# Cell 1: ì„¤ì¹˜
!git clone https://github.com/openvla/openvla.git
%cd openvla
!python experiments/robot/libero/colab_setup_libero.py

# Cell 2: GPU í™•ì¸
import torch
print(f"GPU: {torch.cuda.get_device_name(0)}")
print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

# Cell 3: Evaluation ì‹¤í–‰
!python experiments/robot/libero/run_libero_eval.py \
  --model_family openvla \
  --pretrained_checkpoint openvla/openvla-7b-finetuned-libero-spatial \
  --task_suite_name libero_spatial \
  --center_crop True \
  --load_in_8bit True \
  --num_trials_per_task 10

# Cell 4: ê²°ê³¼ í™•ì¸
!cat experiments/logs/*.txt | tail -20
```

---

## English Guide

### ğŸ¯ Overview

This guide explains how to run OpenVLA's LIBERO Simulation Benchmark Evaluations on Google Colab and solve common issues.

### âš ï¸ Common Issues

When running LIBERO evaluation on Colab, you may encounter:

1. **Flash Attention 2 Compatibility**
   - Flash Attention 2 may not be supported on Colab GPUs (especially T4)
   - Installation failures due to CUDA version mismatch

2. **8-bit Quantization Errors**
   - Conflicts between `bitsandbytes` library and transformers versions
   - CUDA kernel loading failures

3. **Dependency Compatibility**
   - Version mismatches in PyTorch, transformers, tokenizers
   - Conflicts with Colab's pre-installed packages

4. **Out of Memory**
   - Insufficient memory on T4 GPU (16GB) for 7B model
   - Requires ~14GB even with bfloat16

### ğŸš€ Quick Start (Run in Colab)

#### Step 1: Clone Repository and Setup

```bash
# Run in Colab notebook
!git clone https://github.com/openvla/openvla.git
%cd openvla

# Run Colab-specific setup script
!python experiments/robot/libero/colab_setup_libero.py
```

This script automatically:
- Detects GPU type (T4, V100, A100, etc.)
- Installs appropriate dependency versions
- Attempts to install Flash Attention (OK if it fails)
- Installs LIBERO and required packages
- Provides troubleshooting tips

#### Step 2: Run Evaluation

**A. For V100/A100 GPUs (without quantization):**
```bash
!python experiments/robot/libero/run_libero_eval.py \
  --model_family openvla \
  --pretrained_checkpoint openvla/openvla-7b-finetuned-libero-spatial \
  --task_suite_name libero_spatial \
  --center_crop True
```

**B. For T4 GPUs (with 8-bit quantization):**
```bash
!python experiments/robot/libero/run_libero_eval.py \
  --model_family openvla \
  --pretrained_checkpoint openvla/openvla-7b-finetuned-libero-spatial \
  --task_suite_name libero_spatial \
  --center_crop True \
  --load_in_8bit True
```

### ğŸ”§ Troubleshooting

#### Flash Attention Errors

```
ValueError: FlashAttention only support fp16 and bf16 data type
```

**Solution**: Use the provided Colab-optimized script. It automatically falls back to eager attention.

```bash
# Replace openvla_utils.py with Colab version
!cp experiments/robot/openvla_utils_colab.py experiments/robot/openvla_utils.py
```

#### 8-bit Quantization Errors

```
RuntimeError: CUDA error: no kernel image is available for execution on the device
```

**Solution 1**: Install latest bitsandbytes
```bash
!pip install bitsandbytes>=0.43.0 --upgrade
```

**Solution 2**: Run without quantization (V100/A100 only)
```bash
# Remove --load_in_8bit flag
```

#### CUDA Out of Memory

```
torch.cuda.OutOfMemoryError: CUDA out of memory
```

**Solution 1**: Use 8-bit quantization
```bash
--load_in_8bit True
```

**Solution 2**: Reduce number of trials
```bash
--num_trials_per_task 10  # Reduced from default 50
```

**Solution 3**: Restart runtime and clear memory
```python
import torch
torch.cuda.empty_cache()
```

#### Dependency Version Conflicts

```
ImportError: cannot import name 'xxx' from 'transformers'
```

**Solution**: Reinstall exact versions
```bash
!pip uninstall -y transformers tokenizers timm
!pip install transformers==4.40.1 tokenizers==0.19.1 timm==0.9.10
```

### ğŸ“Š Running Other Task Suites

```bash
# LIBERO-Object
!python experiments/robot/libero/run_libero_eval.py \
  --model_family openvla \
  --pretrained_checkpoint openvla/openvla-7b-finetuned-libero-object \
  --task_suite_name libero_object \
  --center_crop True \
  --load_in_8bit True

# LIBERO-Goal
!python experiments/robot/libero/run_libero_eval.py \
  --model_family openvla \
  --pretrained_checkpoint openvla/openvla-7b-finetuned-libero-goal \
  --task_suite_name libero_goal \
  --center_crop True \
  --load_in_8bit True

# LIBERO-10 (Long Horizon)
!python experiments/robot/libero/run_libero_eval.py \
  --model_family openvla \
  --pretrained_checkpoint openvla/openvla-7b-finetuned-libero-10 \
  --task_suite_name libero_10 \
  --center_crop True \
  --load_in_8bit True
```

### ğŸ’¡ Colab Pro Tips

1. **GPU Selection**: Runtime > Change runtime type > GPU (T4, V100, or A100)
2. **Monitor Memory Usage**:
   ```python
   !nvidia-smi
   ```
3. **Keep Session Alive**: Be aware that Colab may disconnect automatically
4. **Save Results**: Mount Google Drive to save logs
   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   ```

### ğŸ“ Recommendations for Paper Reproduction

For exact reproduction of paper results:

- **Python**: 3.10.13
- **PyTorch**: 2.2.0
- **transformers**: 4.40.1
- **flash-attn**: 2.5.5
- **GPU**: NVIDIA A100

âš ï¸ **Note**: Exact reproduction may be difficult on Colab's free T4 GPU. Results may vary slightly.

### ğŸ“ Complete Colab Notebook Example

```python
# Cell 1: Installation
!git clone https://github.com/openvla/openvla.git
%cd openvla
!python experiments/robot/libero/colab_setup_libero.py

# Cell 2: Check GPU
import torch
print(f"GPU: {torch.cuda.get_device_name(0)}")
print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

# Cell 3: Run Evaluation
!python experiments/robot/libero/run_libero_eval.py \
  --model_family openvla \
  --pretrained_checkpoint openvla/openvla-7b-finetuned-libero-spatial \
  --task_suite_name libero_spatial \
  --center_crop True \
  --load_in_8bit True \
  --num_trials_per_task 10

# Cell 4: View Results
!cat experiments/logs/*.txt | tail -20
```

---

## ğŸ¤ ë„ì›€ì´ ë” í•„ìš”í•˜ì‹ ê°€ìš”? / Need More Help?

- GitHub Issues: https://github.com/openvla/openvla/issues
- ì´ ê°€ì´ë“œì˜ ë¬¸ì œ: ìƒˆ ì´ìŠˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš” / For issues with this guide: Create a new issue

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤ / License

ì´ ê°€ì´ë“œëŠ” OpenVLA í”„ë¡œì íŠ¸ì˜ ì¼ë¶€ë¡œ MIT License í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

This guide is part of the OpenVLA project and distributed under the MIT License.
