# í™•ì¥ëœ VLA í•™ìŠµ ë¡œë“œë§µ ğŸš€

ë©˜í† ë‹˜ í”¼ë“œë°± ë°˜ì˜ + TACO ì—°êµ¬ ì¤€ë¹„

---

## ğŸ¯ ì „ì²´ í•™ìŠµ êµ¬ì¡°

```
Week 1: Action Pipeline â† ì´ë¯¸ ì‹œì‘í•¨!
â”œâ”€ âœ… Action tokens ì¶”ì¶œ
â”œâ”€ âœ… Un-normalization
â””â”€ ğŸ†• RLDS ë°ì´í„° í¬ë§·

Week 2: Data & Real-time Constraints
â”œâ”€ ğŸ†• RLDS ë°ì´í„° ë¡œë”
â”œâ”€ ğŸ†• Control Frequency (5-10Hz)
â”œâ”€ ğŸ†• Action Chunking (ì—†ìŒì„ ì´í•´)
â””â”€ Vision Encoder

Week 3: TACO Integration
â”œâ”€ Autoregressive Generation
â”œâ”€ LogitsProcessor
â””â”€ TACO ì œì•½ êµ¬í˜„
```

---

## ğŸ“… Week 1: Action Pipeline + RLDS (7ì¼)

### Day 1-2: Action Tokens (ì™„ë£Œ!)
- [x] `practice_action_tokens.py` ì‹¤í–‰
- [x] Un-normalization ìˆ˜ì‹ ì´í•´
- [x] Dataset statistics ì°¾ê¸°

### Day 3-5: RLDS ë°ì´í„° í¬ë§· â­â­â­â­â­

#### ëª©í‘œ:
"RLDSê°€ ë­”ì§€, OpenVLAê°€ ì–´ë–»ê²Œ ë¡œë“œí•˜ëŠ”ì§€" ì´í•´

#### í•™ìŠµ ë‚´ìš©:

**1. RLDSë€?**
- Robot Learning Dataset Standard
- TensorFlow Datasets (tfds) ê¸°ë°˜
- êµ¬ì¡°: `Dataset â†’ Episodes â†’ Steps â†’ {observations, actions, ...}`

**ì˜ˆì‹œ êµ¬ì¡°:**
```python
{
  'episode_0': {
    'steps': [
      {
        'observation': {
          'image': [224, 224, 3],
          'state': [7],  # EEF pose + gripper
        },
        'action': [7],
        'language_instruction': 'pick up the cup',
        'is_first': True,
        'is_last': False,
        'is_terminal': False,
      },
      # ... more steps
    ]
  },
  'episode_1': { ... }
}
```

**2. OpenVLAì˜ RLDS ë¡œë”**

**í•µì‹¬ íŒŒì¼:**
```
prismatic/vla/datasets/rlds/
â”œâ”€â”€ dataset.py              â† make_dataset_from_rlds()
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ data_utils.py       â† get_dataset_statistics()
â””â”€â”€ oxe/
    â”œâ”€â”€ configs.py          â† bridge_orig ì„¤ì •
    â”œâ”€â”€ transforms.py       â† Datasetë³„ ë³€í™˜
    â””â”€â”€ materialize.py      â† OXE dataset ì„¤ì •
```

**3. ì‹¤ìŠµ: RLDS ë°ì´í„° ë¡œë“œ**

íŒŒì¼: `/home/user/openvla/practice_rlds_loading.py`

```python
"""
RLDS ë°ì´í„° ë¡œë”© ì‹¤ìŠµ

ëª©í‘œ:
1. RLDS ë°ì´í„°ì…‹ êµ¬ì¡° ì´í•´
2. OpenVLAì˜ ë°ì´í„° ë¡œë” ì‚¬ìš©ë²•
3. Episode â†’ Steps â†’ Observations/Actions ì¶”ì¶œ
"""

import tensorflow as tf
import tensorflow_datasets as tfds
from prismatic.vla.datasets.rlds.dataset import make_dataset_from_rlds
from prismatic.vla.datasets.rlds.oxe.configs import OXE_DATASET_CONFIGS


# ============================================================
# Step 1: RLDS ë°ì´í„°ì…‹ êµ¬ì¡° íƒìƒ‰
# ============================================================

def explore_rlds_structure(dataset_name: str = "bridge_dataset"):
    """
    RLDS ë°ì´í„°ì…‹ì˜ êµ¬ì¡°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

    ì£¼ì˜: ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
          êµ¬ì¡° ì´í•´ê°€ ëª©ì ì…ë‹ˆë‹¤.
    """
    print("=" * 60)
    print(f"RLDS Dataset: {dataset_name}")
    print("=" * 60)

    # OpenVLAì˜ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¤ê¸°
    if "bridge_orig" in OXE_DATASET_CONFIGS:
        config = OXE_DATASET_CONFIGS["bridge_orig"]
        print("\n[Config]")
        print(f"  Image keys: {config.get('image_obs_keys')}")
        print(f"  State keys: {config.get('state_obs_keys')}")
        print(f"  Action encoding: {config.get('action_encoding')}")

    # RLDS í‘œì¤€ êµ¬ì¡°
    print("\n[Standard RLDS Structure]")
    print("""
    Dataset
    â””â”€â”€ Episodes (trajectories)
        â””â”€â”€ Steps (transitions)
            â”œâ”€â”€ observation
            â”‚   â”œâ”€â”€ image_0: [H, W, 3]
            â”‚   â”œâ”€â”€ image_1: [H, W, 3] (optional)
            â”‚   â””â”€â”€ state: [state_dim]
            â”œâ”€â”€ action: [action_dim]
            â”œâ”€â”€ language_instruction: str
            â”œâ”€â”€ is_first: bool
            â”œâ”€â”€ is_last: bool
            â””â”€â”€ is_terminal: bool
    """)


# ============================================================
# Step 2: OpenVLA ë°ì´í„° ë¡œë” ì‚¬ìš©
# ============================================================

def understand_data_pipeline():
    """
    OpenVLAê°€ RLDS ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ëŠ”ì§€ ì´í•´
    """
    print("\n" + "=" * 60)
    print("OpenVLA Data Pipeline")
    print("=" * 60)

    print("""
    [Step 1] RLDS ë¡œë“œ
    â”œâ”€ make_dataset_from_rlds()
    â””â”€ TensorFlow Dataset ìƒì„±

    [Step 2] Dataset-specific Transform
    â”œâ”€ bridge_orig_dataset_transform()
    â”‚  â”œâ”€ Action ë³€í™˜ (gripper binarization)
    â”‚  â”œâ”€ State ë¶„ë¦¬ (EEF vs gripper)
    â”‚  â””â”€ Action relabeling
    â””â”€ Output: í‘œì¤€í™”ëœ í˜•ì‹

    [Step 3] Normalization
    â”œâ”€ get_dataset_statistics()
    â”‚  â””â”€ Compute q01, q99 for actions
    â””â”€ normalize_action_and_proprio()
       â””â”€ action â†’ [-1, 1]

    [Step 4] Action Tokenization
    â”œâ”€ ActionTokenizer(action)
    â””â”€ ì—°ì†ê°’ â†’ 256 bins â†’ token IDs

    [Step 5] Prompt ìƒì„±
    â””â”€ "What action ... ? ASSISTANT: <tokens>"
    """)


# ============================================================
# Step 3: Bridge Dataset ì˜ˆì œ
# ============================================================

def bridge_dataset_example():
    """
    Bridge ë°ì´í„°ì…‹ì˜ ì‹¤ì œ êµ¬ì¡°
    """
    print("\n" + "=" * 60)
    print("Bridge Dataset ì˜ˆì œ")
    print("=" * 60)

    print("""
    [Episode ì˜ˆì‹œ]

    Task: "pick up the blue block"

    Step 0:
      observation:
        image_0: [256, 256, 3]  â† 3ì¸ì¹­ ì¹´ë©”ë¼
        image_1: [256, 256, 3]  â† ë‹¤ë¥¸ ê°ë„
        state: [7]              â† [x, y, z, roll, pitch, yaw, gripper]
      action: [7]               â† [Î”x, Î”y, Î”z, Î”roll, Î”pitch, Î”yaw, gripper_cmd]
      language_instruction: "pick up the blue block"
      is_first: True

    Step 1:
      observation: { ... }      â† ë¡œë´‡ì´ ì¡°ê¸ˆ ì›€ì§ì¸ í›„
      action: [7]
      is_first: False

    ...

    Step N:
      observation: { ... }      â† ë¬¼ì²´ë¥¼ ì¡ìŒ
      action: [7]
      is_last: True
      is_terminal: True


    [Action ì˜ë¯¸]
    - action[0:3]: EEFì˜ XYZ ë¸íƒ€ ì´ë™ (meters)
    - action[3:6]: Roll-Pitch-Yaw ë¸íƒ€ íšŒì „ (radians)
    - action[6]:   Gripper ëª…ë ¹ (0=close, 1=open)

    [ì¤‘ìš”!]
    - ActionsëŠ” **ìƒëŒ€ê°’(delta)**: "í˜„ì¬ ìœ„ì¹˜ì—ì„œ ì–¼ë§ˆë‚˜ ì›€ì§ì¼ì§€"
    - GripperëŠ” **ì ˆëŒ€ê°’**: "ì—´ë¦¼/ë‹«í˜ ìƒíƒœ"
    - ì´ê²Œ absolute_action_mask = [False]*6 + [True]ì¸ ì´ìœ !
    """)


# ============================================================
# Step 4: RLDS â†’ OpenVLA ë³€í™˜ ê³¼ì •
# ============================================================

def transformation_pipeline():
    """
    RLDS ì›ë³¸ â†’ OpenVLA ì…ë ¥ ë³€í™˜ ê³¼ì •
    """
    print("\n" + "=" * 60)
    print("Transformation Pipeline")
    print("=" * 60)

    print("""
    [1] ì›ë³¸ RLDS (Bridge)
    {
      'observation': {
        'image': [256, 256, 3],
        'state': [7]  # [x, y, z, r, p, y, gripper]
      },
      'action': [7],  # [Î”x, Î”y, Î”z, Î”r, Î”p, Î”y, gripper_continuous]
      'language_instruction': 'pick up the cup'
    }

    â†“ bridge_orig_dataset_transform()

    [2] ë³€í™˜ í›„
    {
      'observation': {
        'image_0': [224, 224, 3],         â† Resize
        'image_1': [224, 224, 3],
        'EEF_state': [6],                 â† state[:6]
        'gripper_state': [1],             â† state[-1:]
      },
      'action': [7],                      â† Gripper binarized
      'task': {
        'language_instruction': 'pick up the cup'
      }
    }

    â†“ normalize_action_and_proprio()

    [3] ì •ê·œí™”
    {
      'action': [-0.3, 0.5, ..., 1.0],   â† [-1, 1] ë²”ìœ„
      ...
    }

    â†“ ActionTokenizer

    [4] í† í°í™”
    "What action should the robot take to pick up the cup?\nASSISTANT: <tok_1><tok_2>...<tok_7>"
    """)


# ============================================================
# Step 5: ì§ì ‘ í•´ë³´ê¸°
# ============================================================

def exercise_understanding_rlds():
    """
    ì—°ìŠµ ë¬¸ì œ: RLDS êµ¬ì¡° ì´í•´
    """
    print("\n" + "=" * 60)
    print("ì—°ìŠµ ë¬¸ì œ")
    print("=" * 60)

    print("""
    [ë¬¸ì œ 1] Episode vs Step

    Q: Bridge ë°ì´í„°ì…‹ì—ì„œ 1ê°œ episodeëŠ” ëª‡ ê°œì˜ stepsë¡œ êµ¬ì„±ë˜ë‚˜?
    A: í‰ê·  50-100 steps (READMEì— "50 episodes per task" ì–¸ê¸‰)

    Q: ê° stepì€ ëª‡ Hzë¡œ ìˆ˜ì§‘ë˜ì—ˆë‚˜?
    A: 5-10Hz (READMEì˜ "control frequency" ì°¸ê³ )

    Q: ë”°ë¼ì„œ 1ê°œ episodeëŠ” ì•½ ëª‡ ì´ˆì§œë¦¬ ë°ëª¨ì¸ê°€?
    A: 50 steps Ã· 5Hz = 10ì´ˆ ì •ë„


    [ë¬¸ì œ 2] Action êµ¬ì¡°

    ë‹¤ìŒ RLDS stepì´ ì£¼ì–´ì¡Œì„ ë•Œ:

    {
      'observation': {'state': [0.5, 0.3, 0.2, 0, 0, 0, 0.0]},
      'action': [0.01, -0.02, 0.0, 0, 0, 0, 1.0]
    }

    Q1: ë¡œë´‡ì˜ í˜„ì¬ EEF ìœ„ì¹˜ëŠ”?
    A1: (x=0.5, y=0.3, z=0.2)

    Q2: ë‹¤ìŒ stepì—ì„œ ë¡œë´‡ì€ ì–´ë””ë¡œ ì´ë™í•˜ë‚˜?
    A2: (x=0.51, y=0.28, z=0.2)  # actionì€ delta!

    Q3: GripperëŠ” ì–´ë–»ê²Œ ë˜ë‚˜?
    A3: ì—´ë¦¼ (1.0 = open)


    [ë¬¸ì œ 3] TACO ì—°ê²°

    Q: TACOë¡œ "Xì¶•ìœ¼ë¡œ 5cmë§Œ ì´ë™" ì œì•½ì„ ê±¸ ë•Œ,
       RLDSì˜ ì–´ëŠ í•„ë“œë¥¼ ì œì–´í•´ì•¼ í•˜ë‚˜?

    A: action[0] (Xì¶• delta)
       - ì •ê·œí™” ê³µê°„ì—ì„œ 0.05mì— í•´ë‹¹í•˜ëŠ” ê°’ìœ¼ë¡œ logits ì¡°ì •
       - í•˜ì§€ë§Œ ë‹¤ë¥¸ ì°¨ì›(Y, Z, rotation)ì€ ììœ ë¡­ê²Œ
    """)


# ============================================================
# Main
# ============================================================

def main():
    """ì „ì²´ ì‹¤ìŠµ ì‹¤í–‰"""
    explore_rlds_structure()
    understand_data_pipeline()
    bridge_dataset_example()
    transformation_pipeline()
    exercise_understanding_rlds()

    print("\n" + "=" * 60)
    print("ë‹¤ìŒ ë‹¨ê³„")
    print("=" * 60)
    print("""
    1. ì‹¤ì œ RLDS ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ì„ íƒì‚¬í•­):
       - Bridge V2: https://rail.eecs.berkeley.edu/datasets/bridge_release/data/tfds/

    2. OpenVLA ì½”ë“œ ì½ê¸°:
       - prismatic/vla/datasets/rlds/dataset.py:204-251
       - prismatic/vla/datasets/rlds/oxe/transforms.py:61-86

    3. ë‹¤ìŒ ì£¼ì œë¡œ:
       - Control Frequency (5-10Hz)
       - Action Chunking
    """)


if __name__ == "__main__":
    main()
