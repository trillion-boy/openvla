"""
Dataset Statistics íƒìƒ‰
ëª©í‘œ: OpenVLAì˜ dataset_statistics.json íŒŒì¼ ì´í•´
- íŒŒì¼ êµ¬ì¡°
- ê° í•„ë“œì˜ ì˜ë¯¸
- Un-normalizationì— ì‚¬ìš©ë˜ëŠ” ë°©ë²•
ê¸°ë°˜: prismatic/vla/datasets/rlds/utils/data_utils.py:185-293
"""

import json
import numpy as np
from pathlib import Path


def load_and_explore_statistics(stats_file: str = "example_dataset_statistics.json"):
    """
    Dataset statistics íŒŒì¼ ë¡œë“œ ë° íƒìƒ‰
    """
    print("=" * 70)
    print("Dataset Statistics íƒìƒ‰")
    print("=" * 70)

    # íŒŒì¼ ë¡œë“œ
    with open(stats_file, 'r') as f:
        all_stats = json.load(f)

    print(f"\nğŸ“„ íŒŒì¼: {stats_file}")
    print(f"í¬í•¨ëœ ë°ì´í„°ì…‹: {list(all_stats.keys())}")

    # ê° ë°ì´í„°ì…‹ë³„ë¡œ íƒìƒ‰
    for dataset_name, dataset_stats in all_stats.items():
        explore_dataset(dataset_name, dataset_stats)


def explore_dataset(dataset_name: str, dataset_stats: dict):
    """
    ê°œë³„ ë°ì´í„°ì…‹ í†µê³„ íƒìƒ‰
    """
    print("\n" + "=" * 70)
    print(f"Dataset: {dataset_name}")
    print("=" * 70)

    # Action statistics
    if "action" in dataset_stats:
        print("\n[Action Statistics]")
        action_stats = dataset_stats["action"]

        print("\ní•„ë“œ ì„¤ëª…:")
        print("  - mean:   ê° ì°¨ì›ì˜ í‰ê· ê°’")
        print("  - std:    ê° ì°¨ì›ì˜ í‘œì¤€í¸ì°¨")
        print("  - min:    ìµœì†Ÿê°’ (ì ˆëŒ€ ìµœì†Ÿê°’)")
        print("  - max:    ìµœëŒ“ê°’ (ì ˆëŒ€ ìµœëŒ“ê°’)")
        print("  - q01:    1% quantile (outlier ì œê±°ìš©)")
        print("  - q99:    99% quantile (outlier ì œê±°ìš©)")
        print("  - mask:   ì •ê·œí™” ì ìš© ì—¬ë¶€ (True=ì •ê·œí™”, False=ê·¸ëŒ€ë¡œ)")

        # ë°°ì—´ë¡œ ë³€í™˜
        q01 = np.array(action_stats["q01"])
        q99 = np.array(action_stats["q99"])
        mean = np.array(action_stats["mean"])
        std = np.array(action_stats["std"])
        mask = np.array(action_stats["mask"])

        print(f"\nAction ì°¨ì› ìˆ˜: {len(q01)}")
        print(f"\ní†µê³„ê°’ (7ê°œ ì°¨ì›):")
        print(f"  q01: {q01}")
        print(f"  q99: {q99}")
        print(f"  mean: {mean}")
        print(f"  std: {std}")
        print(f"  mask: {mask}")

        # Action ë²”ìœ„ ë¶„ì„
        print(f"\nê° ì°¨ì›ì˜ ìœ íš¨ ë²”ìœ„ (q99 - q01):")
        action_range = q99 - q01
        for i, r in enumerate(action_range):
            dim_name = get_dimension_name(i, dataset_name)
            print(f"  [{i}] {dim_name:20s}: {r:.6f}")

        # Mask ì„¤ëª…
        print(f"\nì •ê·œí™” ë§ˆìŠ¤í¬:")
        for i, m in enumerate(mask):
            dim_name = get_dimension_name(i, dataset_name)
            status = "ì •ê·œí™”í•¨" if m else "ê·¸ëŒ€ë¡œ"
            print(f"  [{i}] {dim_name:20s}: {status}")

        # ì™œ gripperëŠ” ì •ê·œí™” ì•ˆ í•˜ë‚˜?
        if not mask[-1]:
            print(f"\nğŸ’¡ Gripper(ì°¨ì› 6)ë¥¼ ì •ê·œí™” ì•ˆ í•˜ëŠ” ì´ìœ :")
            print(f"   - GripperëŠ” ì´ë¯¸ [0, 1] ë˜ëŠ” {{-1, 1}} ë²”ìœ„ë¡œ í‘œì¤€í™”ë˜ì–´ ìˆìŒ")
            print(f"   - 0 = ë‹«í˜(close), 1 = ì—´ë¦¼(open)")
            print(f"   - ì¶”ê°€ ì •ê·œí™” ë¶ˆí•„ìš”!")

    # Dataset ë©”íƒ€ë°ì´í„°
    if "num_transitions" in dataset_stats:
        print(f"\n[Dataset ë©”íƒ€ë°ì´í„°]")
        print(f"  ì´ transitions: {dataset_stats['num_transitions']:,}")
        print(f"  ì´ trajectories: {dataset_stats['num_trajectories']:,}")
        avg_steps = dataset_stats['num_transitions'] / dataset_stats['num_trajectories']
        print(f"  í‰ê·  trajectory ê¸¸ì´: {avg_steps:.1f} steps")


def get_dimension_name(dim: int, dataset_name: str) -> str:
    """
    ì°¨ì› ë²ˆí˜¸ â†’ ì˜ë¯¸ ìˆëŠ” ì´ë¦„ ë³€í™˜
    """
    # Bridge datasetì˜ ê²½ìš°
    if "bridge" in dataset_name.lower():
        names = [
            "X-axis delta (m)",
            "Y-axis delta (m)",
            "Z-axis delta (m)",
            "Roll delta (rad)",
            "Pitch delta (rad)",
            "Yaw delta (rad)",
            "Gripper (0/1)"
        ]
    else:
        names = [f"Dim {dim}" for dim in range(7)]

    return names[dim] if dim < len(names) else f"Dim {dim}"


def demonstrate_unnormalization():
    """
    Dataset statisticsë¥¼ ì‚¬ìš©í•œ un-normalization ì˜ˆì œ
    """
    print("\n" + "=" * 70)
    print("Un-normalization ì‹¤ìŠµ")
    print("=" * 70)

    # Statistics ë¡œë“œ
    with open("example_dataset_statistics.json", 'r') as f:
        stats = json.load(f)

    bridge_stats = stats["bridge_orig"]["action"]
    q01 = np.array(bridge_stats["q01"])
    q99 = np.array(bridge_stats["q99"])
    mask = np.array(bridge_stats["mask"])

    # ì •ê·œí™”ëœ action (ì˜ˆì‹œ)
    normalized_actions = np.array([0.5, -0.3, 0.8, 0.0, -1.0, 1.0, 0.9])

    print(f"\nì…ë ¥ (ì •ê·œí™”ëœ actions): {normalized_actions}")
    print(f"ë²”ìœ„: [-1, 1]")

    # Un-normalization (openvla.py:97-101 ë°©ì‹)
    real_actions = 0.5 * (normalized_actions + 1) * (q99 - q01) + q01

    # Mask ì ìš© (gripperëŠ” ê·¸ëŒ€ë¡œ)
    real_actions = np.where(mask, real_actions, normalized_actions)

    print(f"\nì¶œë ¥ (ì‹¤ì œ ë¡œë´‡ ëª…ë ¹): {real_actions}")
    print(f"\nì°¨ì›ë³„ í•´ì„:")
    for i in range(7):
        dim_name = get_dimension_name(i, "bridge_orig")
        print(f"  [{i}] {dim_name:20s}: {real_actions[i]:+.6f}")

    # ê²€ì¦: ë²”ìœ„ í™•ì¸
    print(f"\nâœ… ê²€ì¦:")
    for i in range(6):  # Gripper ì œì™¸
        in_range = q01[i] <= real_actions[i] <= q99[i]
        status = "âœ“" if in_range else "âœ—"
        print(f"  [{i}] {status} q01 <= action <= q99: {in_range}")


def compare_normalization_methods():
    """
    ë‹¤ë¥¸ ì •ê·œí™” ë°©ë²• ë¹„êµ
    """
    print("\n" + "=" * 70)
    print("ì •ê·œí™” ë°©ë²• ë¹„êµ")
    print("=" * 70)

    # ì˜ˆì œ ê°’
    action = 0.025  # 2.5cm
    q01, q99 = -0.033, 0.032
    mean, std = -0.0005, 0.013

    print(f"\nì›ë³¸ action: {action:.4f} m (2.5cm)")
    print(f"q01={q01:.4f}, q99={q99:.4f}")
    print(f"mean={mean:.4f}, std={std:.4f}")

    # Method 1: BOUNDS (Min-Max)
    normalized_bounds = 2 * (action - q01) / (q99 - q01) - 1
    print(f"\n[1] BOUNDS (Min-Max):")
    print(f"    norm = 2 * (x - min) / (max - min) - 1")
    print(f"    ê²°ê³¼: {normalized_bounds:.4f}")

    # Method 2: BOUNDS_Q99 (OpenVLA ì‚¬ìš©)
    normalized_q99 = 2 * (action - q01) / (q99 - q01) - 1
    print(f"\n[2] BOUNDS_Q99 (OpenVLA) â­:")
    print(f"    norm = 2 * (x - q01) / (q99 - q01) - 1")
    print(f"    ê²°ê³¼: {normalized_q99:.4f}")
    print(f"    íŠ¹ì§•: Outlier ì œê±°, robust")

    # Method 3: NORMAL (Z-score)
    normalized_zscore = (action - mean) / std
    print(f"\n[3] NORMAL (Z-score):")
    print(f"    norm = (x - mean) / std")
    print(f"    ê²°ê³¼: {normalized_zscore:.4f}")
    print(f"    íŠ¹ì§•: ë²”ìœ„ê°€ [-1, 1]ë¡œ ì œí•œ ì•ˆ ë¨!")

    print(f"\nğŸ’¡ OpenVLAê°€ BOUNDS_Q99ë¥¼ ì“°ëŠ” ì´ìœ :")
    print(f"   1. Outlierì— robust")
    print(f"   2. í•­ìƒ [-1, 1] ë²”ìœ„ (tokenizationì— ìœ ë¦¬)")
    print(f"   3. ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°ëŠ” [-1, 1] ì•ˆì— ë“¤ì–´ì˜´")


def practical_exercise():
    """
    ì‹¤ì „ ì—°ìŠµ: íŠ¹ì • ë¡œë´‡ ëª…ë ¹ì„ ì •ê·œí™” ê³µê°„ìœ¼ë¡œ ë³€í™˜
    """
    print("\n" + "=" * 70)
    print("ì‹¤ì „ ì—°ìŠµ: ë¡œë´‡ ëª…ë ¹ â†’ ì •ê·œí™” ê°’")
    print("=" * 70)

    # Statistics ë¡œë“œ
    with open("example_dataset_statistics.json", 'r') as f:
        stats = json.load(f)

    bridge_stats = stats["bridge_orig"]["action"]
    q01 = np.array(bridge_stats["q01"])
    q99 = np.array(bridge_stats["q99"])

    print("\në¬¸ì œ: ë¡œë´‡ì—ê²Œ ë‹¤ìŒ ëª…ë ¹ì„ ë‚´ë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤:")
    print("  - Xì¶•ìœ¼ë¡œ +2cm ì´ë™")
    print("  - Yì¶•ìœ¼ë¡œ -1cm ì´ë™")
    print("  - Zì¶• ë³€í™” ì—†ìŒ")
    print("  - íšŒì „ ì—†ìŒ")
    print("  - Gripper ì—´ê¸°")

    # ì‹¤ì œ ëª…ë ¹ (meters)
    real_command = np.array([
        0.02,   # X: +2cm
        -0.01,  # Y: -1cm
        0.0,    # Z: 0
        0.0,    # Roll: 0
        0.0,    # Pitch: 0
        0.0,    # Yaw: 0
        1.0     # Gripper: open
    ])

    print(f"\nì‹¤ì œ ëª…ë ¹ (meters/rad): {real_command}")

    # Forward: ì •ê·œí™”
    normalized_command = 2 * (real_command - q01) / (q99 - q01) - 1

    # GripperëŠ” ê·¸ëŒ€ë¡œ
    normalized_command[6] = real_command[6]

    print(f"\nì •ê·œí™”ëœ ëª…ë ¹: {normalized_command}")
    print(f"\nê° ì°¨ì›:")
    for i in range(7):
        dim_name = get_dimension_name(i, "bridge_orig")
        print(f"  [{i}] {dim_name:20s}: {real_command[i]:+.4f} â†’ {normalized_command[i]:+.4f}")

    # ê²€ì¦: ì—­ë³€í™˜
    recovered = 0.5 * (normalized_command[:6] + 1) * (q99[:6] - q01[:6]) + q01[:6]
    recovered = np.append(recovered, normalized_command[6])

    print(f"\nâœ… ì—­ë³€í™˜ ê²€ì¦:")
    print(f"  ì›ë³¸: {real_command}")
    print(f"  ë³µì›: {recovered}")
    print(f"  ì˜¤ì°¨: {np.abs(real_command - recovered)}")


if __name__ == "__main__":
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not Path("example_dataset_statistics.json").exists():
        print("âŒ example_dataset_statistics.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        print("   ë¨¼ì € ì´ íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
        exit(1)

    # ì „ì²´ íƒìƒ‰
    load_and_explore_statistics()

    # Un-normalization ì‹¤ìŠµ
    demonstrate_unnormalization()

    # ì •ê·œí™” ë°©ë²• ë¹„êµ
    compare_normalization_methods()

    # ì‹¤ì „ ì—°ìŠµ
    practical_exercise()

    print("\n" + "=" * 70)
    print("âœ… ì™„ë£Œ!")
    print("=" * 70)
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("  1. ì‹¤ì œ OpenVLA ëª¨ë¸ì˜ dataset_statistics.json ë‹¤ìš´ë¡œë“œ")
    print("  2. practice_action_tokens.pyì™€ í•¨ê»˜ ì‚¬ìš©")
    print("  3. ì‹¤ì œ ëª¨ë¸ ì¶”ë¡  ì‹œ un-normalization ì ìš©")
