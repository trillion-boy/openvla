"""
OpenVLA ì „ì²´ Pipeline ì‹œë®¬ë ˆì´ì…˜ (ëª¨ë¸ ì—†ì´)

ëª©í‘œ: ì‹¤ì œ ëª¨ë¸ ì—†ì´ë„ ì „ì²´ íë¦„ ì²´í—˜
1. ì´ë¯¸ì§€ + ëª…ë ¹ì–´ ì…ë ¥
2. Action tokens ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)
3. Token â†’ Normalized action
4. Un-normalization â†’ ì‹¤ì œ ë¡œë´‡ ëª…ë ¹

GPU ë¶ˆí•„ìš”, numpyë§Œìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥
"""

import numpy as np
import json
from pathlib import Path


# ============================================================
# SimpleActionTokenizer (ì´ì „ ì½”ë“œ ì¬ì‚¬ìš©)
# ============================================================

class SimpleActionTokenizer:
    """ê¸°ë°˜: prismatic/vla/action_tokenizer.py"""

    def __init__(self, vocab_size: int = 32000, n_bins: int = 256):
        self.vocab_size = vocab_size
        self.n_bins = n_bins
        self.bins = np.linspace(-1, 1, n_bins + 1)
        self.bin_centers = (self.bins[:-1] + self.bins[1:]) / 2.0

    def decode_token_ids_to_actions(self, token_ids: np.ndarray) -> np.ndarray:
        """Token IDs â†’ ì •ê·œí™” action"""
        discretized_actions = token_ids - (self.vocab_size - self.n_bins)
        discretized_actions = np.clip(discretized_actions, 0, self.n_bins - 1)
        return self.bin_centers[discretized_actions]


# ============================================================
# OpenVLA Pipeline ì‹œë®¬ë ˆì´ì…˜
# ============================================================

class OpenVLASimulator:
    """
    ì‹¤ì œ OpenVLA ëª¨ë¸ì˜ ë™ì‘ì„ ì‹œë®¬ë ˆì´ì…˜

    ê¸°ë°˜: prismatic/models/vlas/openvla.py:50-103
    """

    def __init__(self, dataset_statistics_path: str):
        # Dataset statistics ë¡œë“œ
        with open(dataset_statistics_path, 'r') as f:
            self.dataset_statistics = json.load(f)

        # Action tokenizer ì´ˆê¸°í™”
        self.action_tokenizer = SimpleActionTokenizer(vocab_size=32000, n_bins=256)

        print("âœ… OpenVLA Simulator ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹: {list(self.dataset_statistics.keys())}")

    def predict_action(self,
                      image_description: str,
                      instruction: str,
                      unnorm_key: str = "bridge_orig",
                      simulation_mode: str = "random") -> dict:
        """
        Action ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜

        Args:
            image_description: ì´ë¯¸ì§€ ì„¤ëª… (ì‹¤ì œ ì´ë¯¸ì§€ ëŒ€ì‹ )
            instruction: ë¡œë´‡ ëª…ë ¹ì–´
            unnorm_key: Dataset ì´ë¦„
            simulation_mode: "random" ë˜ëŠ” "specific"

        Returns:
            dict: ì „ì²´ pipeline ê²°ê³¼
        """
        print("\n" + "=" * 70)
        print("ğŸ¤– OpenVLA Action Prediction")
        print("=" * 70)

        # Step 1: ì…ë ¥ ì²˜ë¦¬
        print(f"\n[ì…ë ¥]")
        print(f"  ì´ë¯¸ì§€: {image_description}")
        print(f"  ëª…ë ¹ì–´: {instruction}")
        print(f"  Dataset: {unnorm_key}")

        # Step 2: Action tokens ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)
        # ì‹¤ì œë¡œëŠ” vla.generate()ê°€ ì‹¤í–‰ë¨
        print(f"\n[Step 1] ëª¨ë¸ì´ action tokens ìƒì„± ì¤‘... (ì‹œë®¬ë ˆì´ì…˜)")

        if simulation_mode == "random":
            # ëœë¤ í† í° ìƒì„± (realistic range)
            action_token_ids = np.random.randint(31744, 32000, size=7)
        else:
            # íŠ¹ì • í† í° (ì˜ˆ: ì•½ê°„ì˜ ì „ì§„ ë™ì‘)
            action_token_ids = np.array([31872, 31800, 31850, 31872, 31872, 31872, 31950])

        print(f"  ìƒì„±ëœ token IDs: {action_token_ids}")

        # Step 3: Token â†’ Normalized action
        print(f"\n[Step 2] Token IDs â†’ ì •ê·œí™” action ë³€í™˜")
        normalized_actions = self.action_tokenizer.decode_token_ids_to_actions(action_token_ids)
        print(f"  ì •ê·œí™” actions ([-1, 1]): {normalized_actions}")

        # Step 4: Un-normalization
        print(f"\n[Step 3] Un-normalization (ì •ê·œí™” â†’ ì‹¤ì œ ë¡œë´‡ ëª…ë ¹)")
        action_stats = self.dataset_statistics[unnorm_key]["action"]
        q01 = np.array(action_stats["q01"])
        q99 = np.array(action_stats["q99"])
        mask = np.array(action_stats.get("mask", [True]*7))

        # openvla.py:97-101ì˜ ê³µì‹
        real_actions = 0.5 * (normalized_actions + 1) * (q99 - q01) + q01
        real_actions = np.where(mask, real_actions, normalized_actions)

        print(f"  ì‹¤ì œ actions: {real_actions}")

        # Step 5: í•´ì„
        print(f"\n[Step 4] ë¡œë´‡ ëª…ë ¹ í•´ì„")
        self._interpret_actions(real_actions, unnorm_key)

        # ê²°ê³¼ ë°˜í™˜
        return {
            "action_token_ids": action_token_ids,
            "normalized_actions": normalized_actions,
            "real_actions": real_actions,
            "unnorm_key": unnorm_key
        }

    def _interpret_actions(self, actions: np.ndarray, dataset_name: str):
        """Action ê°’ í•´ì„"""
        dim_names = [
            "X-axis delta (m)",
            "Y-axis delta (m)",
            "Z-axis delta (m)",
            "Roll delta (rad)",
            "Pitch delta (rad)",
            "Yaw delta (rad)",
            "Gripper"
        ]

        for i, (name, value) in enumerate(zip(dim_names, actions)):
            if i < 6:
                print(f"  [{i}] {name:20s}: {value:+.6f}")
            else:
                status = "OPEN" if value > 0.5 else "CLOSE"
                print(f"  [{i}] {name:20s}: {value:.2f} ({status})")

        # ì›€ì§ì„ ìš”ì•½
        print(f"\nğŸ“Š ì›€ì§ì„ ìš”ì•½:")
        if abs(actions[0]) > 0.001:
            direction = "ì•ìœ¼ë¡œ" if actions[0] > 0 else "ë’¤ë¡œ"
            print(f"  - Xì¶•: {direction} {abs(actions[0]*100):.2f}cm ì´ë™")
        if abs(actions[1]) > 0.001:
            direction = "ì™¼ìª½ìœ¼ë¡œ" if actions[1] > 0 else "ì˜¤ë¥¸ìª½ìœ¼ë¡œ"
            print(f"  - Yì¶•: {direction} {abs(actions[1]*100):.2f}cm ì´ë™")
        if abs(actions[2]) > 0.001:
            direction = "ìœ„ë¡œ" if actions[2] > 0 else "ì•„ë˜ë¡œ"
            print(f"  - Zì¶•: {direction} {abs(actions[2]*100):.2f}cm ì´ë™")

        gripper_action = "ì—´ê¸°" if actions[6] > 0.5 else "ë‹«ê¸°"
        print(f"  - Gripper: {gripper_action}")


# ============================================================
# ì‚¬ìš© ì˜ˆì œ
# ============================================================

def example_1_random_action():
    """ì˜ˆì œ 1: ëœë¤ action ìƒì„±"""
    print("\n" + "=" * 70)
    print("ì˜ˆì œ 1: ëœë¤ Action ìƒì„±")
    print("=" * 70)

    simulator = OpenVLASimulator("example_dataset_statistics.json")

    result = simulator.predict_action(
        image_description="ì±…ìƒ ìœ„ì— íŒŒë€ ë¸”ë¡ì´ ìˆìŒ",
        instruction="pick up the blue block",
        unnorm_key="bridge_orig",
        simulation_mode="random"
    )

    return result


def example_2_specific_action():
    """ì˜ˆì œ 2: íŠ¹ì • ë™ì‘ ì‹œë®¬ë ˆì´ì…˜"""
    print("\n" + "=" * 70)
    print("ì˜ˆì œ 2: íŠ¹ì • ë™ì‘ (ì „ì§„ + ê·¸ë¦½)")
    print("=" * 70)

    simulator = OpenVLASimulator("example_dataset_statistics.json")

    result = simulator.predict_action(
        image_description="ì»µì´ 10cm ì•ì— ìˆìŒ",
        instruction="grasp the cup",
        unnorm_key="bridge_orig",
        simulation_mode="specific"
    )

    return result


def example_3_multiple_predictions():
    """ì˜ˆì œ 3: ì—¬ëŸ¬ ë²ˆ ì˜ˆì¸¡ (trajectory)"""
    print("\n" + "=" * 70)
    print("ì˜ˆì œ 3: ì—°ì† Action (Trajectory ì‹œë®¬ë ˆì´ì…˜)")
    print("=" * 70)

    simulator = OpenVLASimulator("example_dataset_statistics.json")

    instructions = [
        "move forward to the object",
        "align with the object",
        "grasp the object",
        "lift the object"
    ]

    print("\nğŸ¬ ì‹œë‚˜ë¦¬ì˜¤: ë¬¼ì²´ ì§‘ê¸°")
    trajectory = []

    for i, instruction in enumerate(instructions):
        print(f"\n--- Step {i+1}: {instruction} ---")
        result = simulator.predict_action(
            image_description=f"í˜„ì¬ ìœ„ì¹˜ì—ì„œ ë¬¼ì²´ê¹Œì§€ ê±°ë¦¬: {10-i*2}cm",
            instruction=instruction,
            unnorm_key="bridge_orig",
            simulation_mode="random"
        )
        trajectory.append(result)

    return trajectory


def compare_datasets():
    """ì˜ˆì œ 4: ë‹¤ë¥¸ ë°ì´í„°ì…‹ ë¹„êµ"""
    print("\n" + "=" * 70)
    print("ì˜ˆì œ 4: ë°ì´í„°ì…‹ë³„ Un-normalization ë¹„êµ")
    print("=" * 70)

    simulator = OpenVLASimulator("example_dataset_statistics.json")

    # ê°™ì€ ì •ê·œí™” actionì„ ë‹¤ë¥¸ dataset statisticsë¡œ ë³€í™˜
    normalized = np.array([0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 1.0])

    print(f"\në™ì¼í•œ ì •ê·œí™” action: {normalized}")

    for dataset_name in ["bridge_orig", "fractal20220817_data"]:
        print(f"\n--- Dataset: {dataset_name} ---")
        stats = simulator.dataset_statistics[dataset_name]["action"]
        q01 = np.array(stats["q01"])
        q99 = np.array(stats["q99"])

        real_actions = 0.5 * (normalized + 1) * (q99 - q01) + q01
        real_actions[6] = normalized[6]  # Gripper

        print(f"  ì‹¤ì œ actions: {real_actions}")
        print(f"  Xì¶• ì´ë™: {real_actions[0]*100:.2f}cm")


# ============================================================
# Main
# ============================================================

if __name__ == "__main__":
    print("=" * 70)
    print("ğŸ¤– OpenVLA Full Pipeline ì‹œë®¬ë ˆì´ì…˜")
    print("=" * 70)
    print("\nì´ ì½”ë“œëŠ” ì‹¤ì œ ëª¨ë¸ ì—†ì´ OpenVLAì˜ ë™ì‘ì„ ì²´í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("GPU ë¶ˆí•„ìš”, numpyë§Œìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥!")

    # íŒŒì¼ í™•ì¸
    if not Path("example_dataset_statistics.json").exists():
        print("\nâŒ example_dataset_statistics.json íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤!")
        exit(1)

    # ì˜ˆì œ ì‹¤í–‰
    print("\n" + "ğŸ¯ " * 20)
    example_1_random_action()

    print("\n" + "ğŸ¯ " * 20)
    example_2_specific_action()

    print("\n" + "ğŸ¯ " * 20)
    example_3_multiple_predictions()

    print("\n" + "ğŸ¯ " * 20)
    compare_datasets()

    print("\n" + "=" * 70)
    print("âœ… ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")
    print("=" * 70)
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("  1. ì´ ì½”ë“œë¡œ action pipeline ì´í•´")
    print("  2. ì‹¤ì œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (GPU í•„ìš”)")
    print("  3. ì‹¤ì œ ì´ë¯¸ì§€ë¡œ ì¶”ë¡  ì‹¤í–‰")
